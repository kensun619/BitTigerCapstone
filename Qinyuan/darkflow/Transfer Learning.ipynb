{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "import cv2\n",
    "# this is how you load an existing yolo model \n",
    "options = {\"model\": \"./cfg/yolo.cfg\", \"load\": \"./weights/yolo.weights\", \"threshold\": 0.1}\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert(size, box):  # size is the desired scale of the input image\n",
    "    dw = 1./size[0]\n",
    "    dh = 1./size[1]\n",
    "    x = (box[0] + box[1])/2.0\n",
    "    y = (box[2] + box[3])/2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training/60091.jpg\n",
      "[214.1664, 192.99996, 261.00032, 224.83332000000001, 1]\n",
      "size of image: width 640, height 360\n",
      "(0.371224, 0.5803240000000001, 0.07317799999999997, 0.08842600000000007)\n",
      "[74.83328, 160.49988, 224.0, 267.4998, 1]\n",
      "size of image: width 640, height 360\n",
      "(0.23346350000000002, 0.5944440000000001, 0.233073, 0.29722200000000004)\n",
      "number of image that does not have label is:\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "# darkflow expect each image comes with one annotation file in the format of \n",
    "# [category number] [object center in X] [object center in Y] [object width in X] [object width in Y]\n",
    "# We need to convert our annotation file into that format\n",
    "# In our annotation fileï¼»box_upper_left_x, box_upper_left_y, box_lower_right_x, box_lower_right_y, class_label]\n",
    "\n",
    "\n",
    "output_dir = 'training/'\n",
    "with open(\"./training/label.idl\") as f:\n",
    "    lines = f.readlines()\n",
    "# print(lines)    \n",
    "label = ()\n",
    "cnt = 0 # count number of images that has no desired object in them\n",
    "flag= 1# setting it to 1 to print debug info\n",
    "for each in lines:\n",
    "    line = json.loads(each)  \n",
    "    image_name = list(line.keys())[0]\n",
    "    txt_name = re.sub(r\".jpg\", r\".txt\",image_name)\n",
    "    txt_outpath = output_dir + txt_name\n",
    "    img_path = output_dir + image_name\n",
    "    if flag == 1: \n",
    "        print(img_path)\n",
    "    txt_outfile = open(txt_outpath, \"w\")\n",
    "    if not list(line.values())[0]:\n",
    "        cnt = cnt+1\n",
    "        #print(\"No label in this image\")\n",
    "    else:\n",
    "         for box in list(line.values())[0]:           \n",
    "            xmin = box[0]\n",
    "            ymin = box[1]\n",
    "            xmax = box[2]\n",
    "            ymax = box[3]\n",
    "            label = box[4]\n",
    "            img = cv2.imread(img_path)\n",
    "            h, w = img.shape[0], img.shape[1]\n",
    "           \n",
    "            b = (float(xmin), float(xmax), float(ymin), float(ymax))\n",
    "            bb = convert((w,h),b)\n",
    "            if flag == 1:\n",
    "                print(box)\n",
    "                print('size of image: width {}, height {}'.format(w,h) )\n",
    "                print(bb)\n",
    "            txt_outfile.write(str(label) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "    flag = 0    \n",
    "    \n",
    "print('number of image that does not have label is:'.format(cnt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "def drawBoxes(img_path, boxes):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 640\n"
     ]
    }
   ],
   "source": [
    "w, h = img.shape[0], img.shape[1]\n",
    "print(w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def parsing(line):\n",
    "    # this function parse the lines for each annotation and return the format for yolo \n",
    "    line = line.rstrip() # remove the trailing /n\n",
    "    line = re.sub(r'\\[|\\]|{|}|\"','',line)\n",
    "    \n",
    "    split_line = line.split(':')\n",
    "    image_name = split_line[0]\n",
    "    annotation = split_line[1]\n",
    "    annotation = annotation.replace(\" \",\"\")\n",
    "    boxes = annotation.split(',')\n",
    "    t = len(boxes)\n",
    "    if t <= 1:\n",
    "        # there is no box in the image\n",
    "        return []\n",
    "    else:\n",
    "        step = int(t/5)\n",
    "        boxes = [boxes[i::step] for i in range(step)]\n",
    "        for each\n",
    "        return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#call this function at transfer folder\n",
    "flow --model /Users/Ken/Documents/BitTiger/Capstone/darkflow/transfer/cfg/yolo_bitTiger.cfg --load weights/yolo.weights --labels /Users/Ken/Documents/BitTiger/Capstone/darkflow/transfer/cfg/label.txt --train --dataset sub_training --annotation sub_training --trainer adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing ./cfg/yolo.bitTiger.cfg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ken/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './cfg/yolo.bitTiger.cfg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e215c96b8c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m            \u001b[0;34m\"img_dir\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"./sub_testing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           }\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtfnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Ken/anaconda/lib/python3.5/site-packages/darkflow/net/build.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, FLAGS, darknet)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdarknet\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                         \u001b[0mdarknet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdarknet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ken/anaconda/lib/python3.5/site-packages/darkflow/dark/darknet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, FLAGS)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parsing {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mdes_parsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdes_parsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ken/anaconda/lib/python3.5/site-packages/darkflow/dark/darknet.py\u001b[0m in \u001b[0;36mparse_cfg\u001b[0;34m(self, model, FLAGS)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mcfg_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg_yielder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_darkop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ken/anaconda/lib/python3.5/site-packages/darkflow/utils/process.py\u001b[0m in \u001b[0;36mcfg_yielder\u001b[0;34m(model, binary)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0myielding\u001b[0m \u001b[0meach\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minformation\u001b[0m \u001b[0mto\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \t\"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inp_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ken/anaconda/lib/python3.5/site-packages/darkflow/utils/process.py\u001b[0m in \u001b[0;36mparser\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './cfg/yolo.bitTiger.cfg'"
     ]
    }
   ],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "# setting up config file: yolo_bitTiger.cfg\n",
    "# under last [convolution] section: number of class is 4, setting output of last layer as (num_class + 5)*5 =45\n",
    "# under [region] section setting classes=4\n",
    "# creating label.txt \n",
    "\n",
    "options = {\"model\":\"./cfg/yolo.bitTiger.cfg\",\n",
    "           \"load\": \"./weights/yolo.weights\", \n",
    "           \"train\":True,\n",
    "           \"annothation\":\"\" ,\n",
    "           \"dataset\":\"./sub_training\",\n",
    "           \"labels\":,\"./label.txt\",\n",
    "           \"img_dir\":\"./sub_testing\"\n",
    "          }\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing for [] \n",
      "[====================>]100%  009963.xml\n",
      "Statistics:\n",
      "Dataset size: 4952\n"
     ]
    }
   ],
   "source": [
    "from darkflow.utils import pascal_voc_clean_xml\n",
    "meta = []\n",
    "result = pascal_voc_clean_xml.pascal_voc_clean_xml('/Users/Ken/Documents/BitTiger/Capstone/darkflow/transfer/VOCdevkit/VOC2007/Annotations', meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-45-3b098b39f3c5>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-45-3b098b39f3c5>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    return dumps\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "# annotation is stored in train.idl file\n",
    "def parse_annotation(ANN, pick, exclusive = False):\n",
    "    print('Parsing for {} {}'.format(\n",
    "            pick, 'exclusively' * int(exclusive)))\n",
    "    dumps = list()\n",
    "    ann_file = '/Users/Ken/Documents/BitTiger/Capstone/darkflow/transfer/sub_training/label.idl'\n",
    "    img_dir = '/Users/Ken/Documents/BitTiger/Capstone/darkflow/transfer/sub_training/'\n",
    "    with open(ann_file) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for each in lines:\n",
    "        all = list()\n",
    "        line = json.loads(each)\t\n",
    "\n",
    "        image_name = list(line.keys())[0]\n",
    "        if not list(line.values())[0]: # no label in annotation\n",
    "            continue\n",
    "        else:\n",
    "            for box in list(line.values())[0]:        \n",
    "                xmin = box[0]\n",
    "                ymin = box[1]\n",
    "                xmax = box[2]\n",
    "                ymax = box[3]\n",
    "                label = box[4]\n",
    "                current = [label, xmin, ymin, xmax, ymax]\n",
    "                all += [current]\n",
    "        img_path = img_dir + image_name \n",
    "        #img = cv2.imread(img_path)\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        h, w = 360, 640\n",
    "        #print(\"No label in this image\")\n",
    "        add = [[image_name,[w,h,all]]]\n",
    "        dumps += add\n",
    "    return dumps\n",
    "    \n",
    "label = ['1','2','3','20']\n",
    "result = parse_annotation('/Users/Ken/Documents/BitTiger/Capstone/darkflow/transfer/sub_training',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['60091.jpg',\n",
       "  [640,\n",
       "   360,\n",
       "   [[1, 214.1664, 192.99996, 261.00032, 224.83332000000001],\n",
       "    [1, 74.83328, 160.49988, 224.0, 267.4998]]]],\n",
       " ['60092.jpg',\n",
       "  [640,\n",
       "   360,\n",
       "   [[1, 15.166656, 197.49996, 80.16640000000001, 233.49996000000002],\n",
       "    [3, 52.250048, 215.49996, 85.49951999999999, 254.5002]]]],\n",
       " ['60094.jpg',\n",
       "  [640,\n",
       "   360,\n",
       "   [[1, 171.33312, 188.49996000000002, 243.8336, 240.66647999999998]]]]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
