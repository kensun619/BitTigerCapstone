{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================>]100%  ./test_post_processing/out/60095.json"
     ]
    }
   ],
   "source": [
    "# The boxes output by the algorithm is based on 416x416 need to rescale back to 640x360\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "#output_path = '.'\n",
    "#pred_path = '.'\n",
    "pred_path = './test_post_processing/out/'\n",
    "output_path = './test_post_processing/'\n",
    "output_img_path = './test_post_processing/out/'\n",
    "    \n",
    "# output_path = './predict_416/'\n",
    "output_name = 'predict_sub.idl'\n",
    "output_file = os.path.join(output_path,output_name)\n",
    "out_f = open(output_file, 'w')\n",
    "img_input_path = './test_post_processing/'\n",
    "# annotations = os.listdir(pred_path)\n",
    "annotations = glob.glob(pred_path + '*.json')\n",
    "# annotations = ['newRight-67564.json']\n",
    "size = len(annotations)\n",
    "\n",
    "network_img_sz = 416\n",
    "img_width = 640\n",
    "img_height = 360\n",
    " \n",
    "img_plot_flag = 1 # draw boxes on img if value is 1\n",
    "\n",
    "\n",
    "for i,file in enumerate(annotations):\n",
    "    sys.stdout.write('\\r')\n",
    "    percentage = 1. * (i+1) / size\n",
    "    progress = int(percentage * 20)\n",
    "    bar_arg = [progress*'=', ' '*(19-progress), percentage*100]\n",
    "    bar_arg += [file]\n",
    "    sys.stdout.write('[{}>{}]{:.0f}%  {}'.format(*bar_arg))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    head, tail = os.path.split(file)\n",
    "    img_name = os.path.splitext(os.path.basename(file))[0] + '.jpg'\n",
    "    if img_plot_flag:\n",
    "        img_file = os.path.join(img_input_path,img_name)\n",
    "        \n",
    "        new_img_file = os.path.join(output_img_path,'pred_'+img_name) \n",
    "        im = cv2.imread(img_file)\n",
    "        # im = cv2.resize(im,(network_img_sz,network_img_sz))\n",
    "    \n",
    "    # actual parsing\n",
    "    #file_path = os.path.join(pred_path,file)\n",
    "    file_path = file\n",
    "    in_file = open(file_path)\n",
    "    all_obj = json.load(in_file)\n",
    "    \n",
    "    prediction = list()\n",
    "    if len(all_obj) is 0: # no boxes are predicted\n",
    "        if img_plot_flag:\n",
    "            cv2.imwrite(new_img_file, im)\n",
    "        newLine = {img_name: []}\n",
    "        out_f.write( json.dumps(newLine) + \"\\n\" )\n",
    "        continue\n",
    "    for obj in all_obj:\n",
    "        label = int(obj['label'])\n",
    "        confidence = obj['confidence']\n",
    "        xmax = obj['bottomright']['x']   # these values are already integers\n",
    "        ymax = obj['bottomright']['y']\n",
    "        xmin = obj['topleft']['x']\n",
    "        ymin = obj['topleft']['y']\n",
    "        newLabels = [xmin, ymin, xmax, ymax, label, confidence]\n",
    "        # We need to resize boxes to original scale\n",
    "        xmax_orig = int(xmax/network_img_sz*img_width)\n",
    "        ymax_orig = int(ymax/network_img_sz*img_height)\n",
    "        xmin_orig = int(xmin/network_img_sz*img_width)\n",
    "        ymin_orig = int(ymin/network_img_sz*img_height)\n",
    "        # newLabels = [xmin_orig, ymin_orig, xmax_orig, ymax_orig, label, confidence]\n",
    "        prediction.append(newLabels)\n",
    "        if img_plot_flag:\n",
    "            cv2.rectangle(im,(xmin,ymin),(xmax,ymax),(255,0,0),2) \n",
    "            # cv2.rectangle(im,(xmin_orig,ymin_orig),(xmax_orig,ymax_orig),(255,0,0),2) \n",
    "            # cv2.putText(im, str(label), (xmin_orig,ymin_orig-10), cv2.FONT_HERSHEY_DUPLEX, 0.4, (255,0,0), 1)    \n",
    "    newLine = {img_name: prediction}    \n",
    "    out_f.write( json.dumps(newLine) + \"\\n\" )\n",
    "    \n",
    "    if img_plot_flag:\n",
    "        cv2.imwrite(new_img_file, im)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check labeling result\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "image_path = './training_aug/'\n",
    "label_file = './comb-label.idl'\n",
    "output_path = './training_aug_verification/'\n",
    "with open(label_file) as f:\n",
    "    lines = f.readlines() \n",
    "    \n",
    "for i, each in enumerate(lines):\n",
    "    sys.stdout.write('\\r')\n",
    "    percentage = 1. * (i+1) / size\n",
    "    progress = int(percentage * 20)\n",
    "    bar_arg = [progress*'=', ' '*(19-progress), percentage*100]\n",
    "    bar_arg += [each]\n",
    "    sys.stdout.write('[{}>{}]{:.0f}%  {}'.format(*bar_arg))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "    line = json.loads(each) \n",
    "    image_name = list(line.keys())[0]\n",
    "    image_file = os.path.join(image_path,image_name)\n",
    "    new_image_file = os.path.join(output_path,image_name)\n",
    "    im = cv2.imread(image_file)\n",
    "    if list(line.values())[0]: #If there is label in annotation\n",
    "        for box in list(line.values())[0]:        \n",
    "            xmin = box[0]\n",
    "            ymin = box[1]\n",
    "            xmax = box[2]\n",
    "            ymax = box[3]\n",
    "            label = box[4]\n",
    "            cv2.rectangle(im,(int(xmin),int(ymin)),(int(xmax),int(ymax)),(255,0,0),2) \n",
    "    cv2.imwrite(new_image_file, im)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing box 0 of image 0\n",
      "IOU is 0.9219350247460808\n",
      "[0.026562499999999822, 0.655555555555555, 3.1687499999999997, 3.7555555555555555]\n",
      "[0.03502549999999971, 0.7277719999999999, 3.029949, 3.863886]\n",
      "Label of prediction is 1, Label of ground truth is 1\n",
      "Processing box 1 of image 0\n",
      "IOU is 0.6227752574882294\n",
      "[0.7734375, 0.3305555555555548, 1.05625, 1.0833333333333333]\n",
      "[0.8259119999999998, 0.5442119999999999, 0.9513139999999995, 1.1495380000000008]\n",
      "Label of prediction is 1, Label of ground truth is 1\n",
      "Processing box 0 of image 1\n",
      "IOU is 0.48377167366383167\n",
      "[0.27968749999999987, 0.125, 0.8125, 2.022222222222222]\n",
      "[0.3990190499999997, 0.4861139999999988, 0.6753798999999998, 1.4083420000000006]\n",
      "Label of prediction is 3, Label of ground truth is 3\n",
      "Processing box 1 of image 1\n",
      "IOU is 0.4815098570625801\n",
      "[0.82265625, 0.5111111111111111, 0.8328125, 1.661111111111111]\n",
      "[0.9682263500000001, 0.7819429999999992, 1.3203073, 1.300000000000001]\n",
      "Label of prediction is 1, Label of ground truth is 1\n",
      "Processing box 0 of image 3\n",
      "IOU is 0.8630131277518915\n",
      "[0.18437500000000018, 0.7277777777777779, 1.3812499999999999, 1.7333333333333332]\n",
      "[0.21653699999999976, 0.7488384999999989, 1.4726659999999996, 1.8837909999999987]\n",
      "Label of prediction is 1, Label of ground truth is 1\n",
      "[0.3333333333333333, 0, 0.0, 0.0]\n",
      "[0.75, 0, 0.0, 0]\n"
     ]
    }
   ],
   "source": [
    "## Given two annotatioin files (one ground truth, one prediction), calculate precision, recall and AP\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "# w h is input width and height\n",
    "# W H is output width and height\n",
    "def convert_to_grid(allobj, W, H, w, h):\n",
    "    cellx = 1. * w / W\n",
    "    celly = 1. * h / H\n",
    "    new_allobj = copy.deepcopy(allobj)\n",
    "    for obj in new_allobj:\n",
    "        centerx = .5*(obj[0]+obj[2]) #xmin, xmax\n",
    "        centery = .5*(obj[1]+obj[3]) #ymin, ymax\n",
    "        cx = centerx / cellx\n",
    "        cy = centery / celly\n",
    "        if cx >= W or cy >= H: return None, None\n",
    "        obj[2] = float(obj[2]-obj[0]) / cellx\n",
    "        obj[3] = float(obj[3]-obj[1]) / celly\n",
    "        #obj[2] = np.sqrt(obj[2])\n",
    "        #obj[3] = np.sqrt(obj[3])\n",
    "        obj[0] = cx - np.floor(cx) # centerx\n",
    "        obj[1] = cy - np.floor(cy) # centery\n",
    "        obj += [int(np.floor(cy) * W + np.floor(cx))] # index in 1d\n",
    "    return new_allobj\n",
    "\n",
    "# these codes are altered from utils/box.py\n",
    "\n",
    "def overlap(x1,w1,x2,w2):\n",
    "    l1 = x1 - w1 / 2.;\n",
    "    l2 = x2 - w2 / 2.;\n",
    "    left = max(l1, l2)\n",
    "    r1 = x1 + w1 / 2.;\n",
    "    r2 = x2 + w2 / 2.;\n",
    "    right = min(r1, r2)\n",
    "    return right - left;\n",
    "\n",
    "# a = [cx, cy, w, h]\n",
    "def box_intersection(a, b):\n",
    "    w = overlap(a[0], a[2], b[0], b[2]);\n",
    "    h = overlap(a[1], a[3], b[1], b[3]);\n",
    "    if w < 0 or h < 0: return 0;\n",
    "    area = w * h;\n",
    "    return area;\n",
    "\n",
    "def box_union(a, b):\n",
    "    i = box_intersection(a, b);\n",
    "    u = a[2] * a[3] + b[2] * b[3] - i;\n",
    "    return u;\n",
    "\n",
    "def box_iou(a, b):\n",
    "    return box_intersection(a, b) / box_union(a, b);\n",
    "\n",
    "pred_path = './test_post_processing/'\n",
    "# pred_path = './training_aug/out/'\n",
    "pred_filename = 'predict_sub.idl'\n",
    "pred_file = os.path.join(pred_path,pred_filename)\n",
    "# load prediction into a dictionary\n",
    "with open(pred_file) as f:\n",
    "        pred_lines = f.readlines()\n",
    "pred = dict()\n",
    "for i, each in enumerate(pred_lines):\n",
    "    line = json.loads(each)\n",
    "    img_name = list(line.keys())[0]\n",
    "    pred_ann = list(line.values())[0]\n",
    "    pred[img_name] = pred_ann\n",
    "    \n",
    "# print(pred)\n",
    "# load ground truth into dictionary    \n",
    "grndtrth_path = './test_post_processing/'\n",
    "grndtrth_filename = 'label_sub.idl'\n",
    "grndtrth_file = os.path.join(grndtrth_path,grndtrth_filename)    \n",
    "with open(grndtrth_file) as f:\n",
    "        grndtrth_lines = f.readlines()\n",
    "truth = dict()\n",
    "for i, each in enumerate(grndtrth_lines):\n",
    "    line = json.loads(each)\n",
    "    img_name = list(line.keys())[0]\n",
    "    grndtrth_ann = list(line.values())[0]\n",
    "    truth[img_name] = grndtrth_ann\n",
    "\n",
    "# print(truth)\n",
    "img_input_path = './test_post_processing/'\n",
    "output_img_path = './test_post_processing/out'\n",
    "#img_name = os.listdir(img_input_path)\n",
    "img_file = list(glob.glob(img_input_path + '*.jpg'))\n",
    "\n",
    "num_boxes = 5\n",
    "# Use this to get the statistics of number of boxes in one grid\n",
    "num_boxes_in_grid = [0]*num_boxes\n",
    "img_plot_flag = 1\n",
    "num_classes = 4\n",
    "\n",
    "out_all = []\n",
    "out_all_label = []\n",
    "pred_all = []\n",
    "pred_all_label = []\n",
    "for i, each_img in enumerate(img_file):\n",
    "    img_name = os.path.basename(each_img)\n",
    "    # img = cv2.imread(each_img)   \n",
    "    # h,w = img.shape\n",
    "    H = 13\n",
    "    W = 13\n",
    "    w = 640\n",
    "    h = 360\n",
    "    if img_name not in pred:\n",
    "        print(img_name + ' not in prediction')\n",
    "        continue\n",
    "    if img_name not in truth:\n",
    "        print(img_name + ' not in ground truth')\n",
    "        continue\n",
    "    pred_ann = pred[img_name]\n",
    "    truth_ann = truth[img_name]\n",
    "    \n",
    "    if img_plot_flag:\n",
    "        img_file = os.path.join(img_input_path,img_name)\n",
    "        new_img_file = os.path.join(output_img_path,'both_'+img_name) \n",
    "        im = cv2.imread(img_file)\n",
    "        if len(truth_ann) > 0:\n",
    "            for box in truth_ann:\n",
    "                cv2.rectangle(im,(int(box[0]),int(box[1])),(int(box[2]),int(box[3])),(0,255,0),2)\n",
    "        if len(pred_ann) > 0:\n",
    "            for box in pred_ann:\n",
    "                cv2.rectangle(im,(int(box[0]),int(box[1])),(int(box[2]),int(box[3])),(255,0,0),2)        \n",
    "        cv2.imwrite(new_img_file, im)\n",
    "        \n",
    "    pred_grid_ann = convert_to_grid(pred_ann, W, H, w, h )\n",
    "    truth_grid_ann = convert_to_grid(truth_ann, W, H, w, h)\n",
    "    # put each annotation into corresponding grids\n",
    "    \n",
    "    # Make the assumption that ground truth and prediction must lie in the same grid\n",
    "    # put prediction into a dictionary, key is the 1d grid location\n",
    "    # You can also use hash look up to do it. But number of boxes in each image is small, it is fine to just use dictionary\n",
    "    pred_1d = dict()\n",
    "    if len(pred_grid_ann) > 0:\n",
    "        for box in pred_grid_ann:\n",
    "            cx = box[0] # centerx\n",
    "            cy = box[1] # centery\n",
    "            gw = box[2] # sqrt(sw)  sw = (xmax-xmin)/w\n",
    "            gh = box[3] # sqrt(sh)\n",
    "            label = box[4]\n",
    "            conf = box[5]\n",
    "            pred_all += [conf]\n",
    "            pred_all_label += [label]\n",
    "            loc_1d = box[6]\n",
    "            if loc_1d in pred_1d :\n",
    "                pred_1d[loc_1d].append([cx, cy, gw, gh, label, conf])\n",
    "            else:    \n",
    "                pred_1d[loc_1d] = [[cx, cy, gw, gh, label, conf]]\n",
    "    \n",
    "    truth_1d = dict()\n",
    "    if len(truth_grid_ann) > 0:\n",
    "        # put ground truth into a dictionary, key is the 1d grid location\n",
    "        for box in truth_grid_ann:\n",
    "            cx = box[0] # centerx\n",
    "            cy = box[1] # centery\n",
    "            gw = box[2] # sw = (xmax-xmin)/w\n",
    "            gh = box[3] # \n",
    "            label = box[4]\n",
    "            loc_1d = box[5]\n",
    "            if loc_1d in truth_1d :\n",
    "                truth_1d[loc_1d].append([cx, cy, gw, gh, label])\n",
    "            else:    \n",
    "                truth_1d[loc_1d] = [[cx, cy, gw, gh, label]]\n",
    "        out = [- math.inf]* len(truth_grid_ann)  \n",
    "        out_label = [0] * len(truth_grid_ann) \n",
    "        # test number of boxes in one grid   \n",
    "        box_cnter = 0\n",
    "        for key, value in truth_1d.items():\n",
    "            if len(value) > num_boxes:\n",
    "                print('Exist grid containing more than {} boxes'.format(num_boxes))\n",
    "            else:\n",
    "                num_boxes_in_grid[len(value)-1] = num_boxes_in_grid[len(value)-1]+1\n",
    "            # calculate precision recall and AP\n",
    "            for each_truth in value: \n",
    "                print('Processing box {} of image {}'.format(box_cnter, i))\n",
    "                out_label[box_cnter] = each_truth[4]\n",
    "                if key in pred_1d:\n",
    "                    # calculate iou between ground truth and prediction\n",
    "                    for each_pred in pred_1d[key]:\n",
    "                        \n",
    "                        \n",
    "                        pred_box = [each_pred[0],each_pred[1],each_pred[2],each_pred[3]]\n",
    "                        truth_box = [each_truth[0],each_truth[1],each_truth[2],each_truth[3]]\n",
    "                        print('IOU is {}'.format(box_iou(pred_box, truth_box)))\n",
    "                        print(pred_box)\n",
    "                        print(truth_box)\n",
    "                        print('Label of prediction is {}, Label of ground truth is {}'.format(each_pred[4], each_truth[4]))\n",
    "                        if box_iou(pred_box, truth_box) > 0.5 and each_pred[4] == each_truth[4]:\n",
    "                            if out[box_cnter] == -math.inf:\n",
    "                                out[box_cnter] = each_pred[5] # store the confidence\n",
    "                            else:\n",
    "                                out[box_cnter] = -math.inf # the ground truth box corresponds to two predictions\n",
    "                        \n",
    "                box_cnter = box_cnter+1    \n",
    "            \n",
    "        out_all+= out\n",
    "        out_all_label+= out_label\n",
    "        \n",
    "\n",
    "label_form = [1,2,3,20]        \n",
    "    # if i is 0: break\n",
    "out_all_label = np.array(out_all_label)\n",
    "out_all = np.array(out_all)\n",
    "pred_all  = np.array(pred_all)\n",
    "pred_all_label = np.array(pred_all_label)\n",
    "\n",
    "prec = [0]*len(label_form)\n",
    "rec = [0]*len(label_form)\n",
    "\n",
    "# ignore AP calculation for now\n",
    "for i in range(len(label_form)):\n",
    "    out_class_idx = out_all_label == label_form[i]\n",
    "    out_class = out_all[out_class_idx]\n",
    "    pred_class_idx = pred_all_label == label_form[i]\n",
    "    pred_class = pred_all[pred_class_idx]\n",
    "    tp = sum(out_class > 0)\n",
    "    if len(out_class) > 0:\n",
    "        rec[i] = tp/len(out_class)\n",
    "    if len(pred_class) > 0:\n",
    "        prec[i] = tp/len(pred_class)\n",
    "        \n",
    "print(prec)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8259119999999998,\n",
       "  0.5442119999999999,\n",
       "  0.27051432494416994,\n",
       "  0.29736509546347245,\n",
       "  1,\n",
       "  95],\n",
       " [0.03502549999999971,\n",
       "  0.7277719999999999,\n",
       "  0.48277634573371553,\n",
       "  0.5451807039872193,\n",
       "  1,\n",
       "  94]]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_grid_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.03671874999999991,\n",
       "  0.6916666666666664,\n",
       "  0.49529031890397374,\n",
       "  0.5,\n",
       "  1,\n",
       "  0.84,\n",
       "  94],\n",
       " [0.8343749999999996,\n",
       "  0.34861111111111054,\n",
       "  0.2904737509655563,\n",
       "  0.29344694769431684,\n",
       "  1,\n",
       "  0.71,\n",
       "  95]]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_grid_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[71, 168, 228, 258, 1, 0.84], [211, 188, 265, 219, 1, 0.71]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[214.1664, 192.99996, 261.00032, 224.83332000000001, 1],\n",
       " [74.83328, 160.49988, 224.0, 267.4998, 1]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{94: [[0.03502549999999971,\n",
       "   0.7277719999999999,\n",
       "   0.48277634573371553,\n",
       "   0.5451807039872193,\n",
       "   1]],\n",
       " 95: [[0.8259119999999998,\n",
       "   0.5442119999999999,\n",
       "   0.27051432494416994,\n",
       "   0.29736509546347245,\n",
       "   1]]}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_1d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_boxes_in_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{94: [[0.03671874999999991,\n",
       "   0.6916666666666664,\n",
       "   0.49529031890397374,\n",
       "   0.5,\n",
       "   1,\n",
       "   0.84]],\n",
       " 95: [[0.8343749999999996,\n",
       "   0.34861111111111054,\n",
       "   0.2904737509655563,\n",
       "   0.29344694769431684,\n",
       "   1,\n",
       "   0.71]]}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "out = [-math.inf]* len(truth_grid_ann) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10833233333333375"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.8343749999999996, 0.34861111111111054, 0.084375, 0.08611111111111111]\n",
    "\n",
    "b = [0.8259119999999998, 0.5442119999999999, 0.07317799999999997, 0.08842600000000007]\n",
    "box_iou(a,b)\n",
    "box_intersection(a,b)\n",
    "overlap(a[0], a[2], b[0], b[2])\n",
    "overlap(a[1], a[3], b[1], b[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.84, -inf]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def overlap(x1,w1,x2,w2):\n",
    "    l1 = x1 - w1 / 2.;\n",
    "    l2 = x2 - w2 / 2.;\n",
    "    left = max(l1, l2)\n",
    "    r1 = x1 + w1 / 2.;\n",
    "    r2 = x2 + w2 / 2.;\n",
    "    right = min(r1, r2)\n",
    "    return right - left;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(key in pred_grid_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "if out[0] is -math.inf:\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.84, 0.71, -inf, -inf, 0.85]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 3, 1, 1]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True  True]\n",
      "[False False False False False]\n",
      "[False False  True False False]\n",
      "[False False False False False]\n"
     ]
    }
   ],
   "source": [
    "label_form = [1,2,3,20]\n",
    "out_all_label = np.array(out_all_label)\n",
    "for i in range(len(label_form)):\n",
    "    out_class_idx = out_all_label == label_form[i]\n",
    "    print(out_class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_class_idx = out_all_label == label_form[i]\n",
    "out_class = out_all[out_class_idx]\n",
    "si = np.argsort(-out_class)\n",
    "so = np.sort(-out_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84, 0.71, -inf, 0.85])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84, 0.71, 0.34, 0.48, 0.32, 0.36, 0.35, 0.59, 0.42, 0.35, 0.85,\n",
       "       0.44, 0.34])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  3,  1,  1,  1,  1, 20,  1, 20, 20])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333333333333333, 0, 0.0, 0.0]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75, 0, 0.0, 0]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./test_post_processing/out/60091.json',\n",
       " './test_post_processing/out/60092.json',\n",
       " './test_post_processing/out/60093.json',\n",
       " './test_post_processing/out/60094.json',\n",
       " './test_post_processing/out/60095.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
